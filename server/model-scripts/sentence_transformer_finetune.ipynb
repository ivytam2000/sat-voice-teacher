{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install Dependencies and Imports**"
      ],
      "metadata": {
        "id": "b7nhVW3TNp6I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwLR8R89M_zH"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pDUQm0fcNdwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/sentence-transformer"
      ],
      "metadata": {
        "id": "V_7ZkORpNf5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer, losses, models, util\n",
        "from sentence_transformers.evaluation import TripletEvaluator\n",
        "from sentence_transformers.readers import InputExample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "import pandas as pd\n",
        "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator"
      ],
      "metadata": {
        "id": "9Q_VvMiQNhaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "dataset_name = \"embedding-data/QQP_triplets\"\n",
        "model_save_path = \"./fine-tune-sentence-transformers\""
      ],
      "metadata": {
        "id": "BNqR_fRsN5ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model and Dataset**"
      ],
      "metadata": {
        "id": "fIuh60SlOLKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(dataset_name)\n",
        "# View first 2 elements of dataset\n",
        "dataset['train']['set'][:2]"
      ],
      "metadata": {
        "id": "6Ub-lyV7OkP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMyvlHIfA15e"
      },
      "outputs": [],
      "source": [
        "X_train_val = []\n",
        "data = dataset['train']['set']\n",
        "for i in range(len(data)):\n",
        "    if data[i]['query'] and len(data[i]['pos']) >= 1 and len(data[i]['pos']) >= 1:\n",
        "        X_train_val.append(InputExample(texts=[data[i]['query'], data[i]['pos'][0], data[i]['neg'][0]]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into 80% training and 20% validation\n",
        "X_train, X_val = train_test_split(X_train_val, train_size=0.8, random_state=33)"
      ],
      "metadata": {
        "id": "pF48Eqm_gCUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "test_batch_size = 8\n",
        "epochs = 5\n",
        "learning_rate = 2e-5\n",
        "warmup_steps = math.ceil(len(X_train)/batch_size * epochs * 0.1)"
      ],
      "metadata": {
        "id": "3VnEV235gNu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(X_train, shuffle=True, batch_size=batch_size)\n",
        "val_evaluator = TripletEvaluator.from_input_examples(X_val, name='sts-val', show_progress_bar=True, write_csv=True, batch_size=test_batch_size)"
      ],
      "metadata": {
        "id": "ZWU0FK8ugUtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-tuning Model**"
      ],
      "metadata": {
        "id": "I8dDeXOAg5Fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(model_name)"
      ],
      "metadata": {
        "id": "oiN2-SOXgwxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = losses.TripletLoss(model=model)"
      ],
      "metadata": {
        "id": "wWLM2Bafg4in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, loss)],\n",
        "    evaluator = val_evaluator,\n",
        "    epochs = epochs,\n",
        "    warmup_steps = warmup_steps,\n",
        "    optimizer_params = {'lr': learning_rate},\n",
        "    output_path = model_save_path\n",
        ")"
      ],
      "metadata": {
        "id": "Nc4nlba-hA2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_metrics_df = pd.read_csv(f'{model_save_path}/eval/triplet_evaluation_sts-val_results.csv')\n",
        "val_metrics_df = val_metrics_df[[\"epoch\", \"accuracy_cosinus\",\t\"accuracy_manhattan\", \"accuracy_euclidean\"]]\n",
        "val_metrics_df"
      ],
      "metadata": {
        "id": "PtxCjZxRhKNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "_YmwI3fVhyNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model\n",
        "model = SentenceTransformer.load('./pic')"
      ],
      "metadata": {
        "id": "Vi50UkFjhMOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 1: Calculating the Accuracy\n",
        "import csv\n",
        "\n",
        "questions = []\n",
        "similar_questions_1 = []\n",
        "similar_questions_2 = []\n",
        "\n",
        "with open('questions_dataset_final.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        questions.append(row[0])\n",
        "        similar_questions_1.append(row[1])\n",
        "        similar_questions_2.append(row[2])\n",
        "\n",
        "# print(questions)\n",
        "# print(similar_questions_1)\n",
        "# print(similar_questions_2)"
      ],
      "metadata": {
        "id": "Sii6sv5Dh-q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reference_sentences = []\n",
        "predicted_sentences = []\n",
        "model = SentenceTransformer(model_name)\n",
        "\n",
        "passage_embedding = model.encode(questions)\n",
        "\n",
        "def get_match(query):\n",
        "  query_embedding = model.encode(query)\n",
        "  sim_scores = util.dot_score(query_embedding, passage_embedding).numpy()[0]\n",
        "  sentence_pos = []\n",
        "  for i in range(len(sim_scores)):\n",
        "      sentence_pos.append({'index': i, 'score': sim_scores[i]})\n",
        "\n",
        "  #sort scores in decreasing order\n",
        "  sentence_pos = sorted(sentence_pos, key=lambda x: x['score'], reverse=True)\n",
        "  most_sim_pos = sentence_pos[0]['index']\n",
        "  return questions[most_sim_pos]\n",
        "\n",
        "for i in range(len(similar_questions_1)):\n",
        "  reference_sentences.append(questions[i])\n",
        "  reference_sentences.append(questions[i])\n",
        "\n",
        "  predicted_sentences.append(get_match(similar_questions_1[i]))\n",
        "  predicted_sentences.append(get_match(similar_questions_2[i]))"
      ],
      "metadata": {
        "id": "xp3Tcjc_iEjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_correct = 0\n",
        "\n",
        "for predicted, reference in zip(predicted_sentences, reference_sentences):\n",
        "    if predicted == reference:\n",
        "        num_correct += 1\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = num_correct / len(predicted_sentences)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "wh2oymOPiGc0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# METHOD 2: STSb performance\n",
        "\n",
        "sts = load_dataset('glue', 'stsb', split='validation')"
      ],
      "metadata": {
        "id": "AE88wwHxiOT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize sentence similarity scores in stsb dataset which range from (0,5) to the range(0,1)\n",
        "sts = sts.map(lambda x: {'label': x['label'] / 5.0})\n"
      ],
      "metadata": {
        "id": "FZlW9acUielm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "for s in sts:\n",
        "    data.append(InputExample(texts=[s['sentence1'], s['sentence2']],label=s['label']))"
      ],
      "metadata": {
        "id": "k6XMin6Vi96V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(data, write_csv=True)\n",
        "# Spearman's Rank Correlation of model on STSb dataset\n",
        "evaluator(model)"
      ],
      "metadata": {
        "id": "QgrWvmnmjU_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}